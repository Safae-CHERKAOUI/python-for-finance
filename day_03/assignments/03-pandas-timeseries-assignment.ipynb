{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning : Time Series Data\n",
    "\n",
    "\n",
    "- A hypothetical company, ABC Financial Services Corp makes financial investment decisions on behalf of it's clients based on the company's economic research. A lot of these decisions involve speculating whether financial instruments will increase or decrease in value in the future.\n",
    "- ABC Corp utilizes several economic indicators but there is one in particular that is heavily weighted in their analysis and that is the [University of Michigan's Consumer Sentiment Survey](https://en.wikipedia.org/wiki/University_of_Michigan_Consumer_Sentiment_Index).\n",
    "- The only problem is that they have to wait for the release of this indicator which erodes some of their competitive advantage in the market and they would like a way to predict this number.\n",
    "- I propose to use a form of Machine Learning (ML) to make Time Series preditions on the final Consumer Sentiment number to be released.\n",
    "- To do this we are going to use other economic indicators (as features) released before and data from various relevant industries to construct a dataset that is ready to run on predictive algorithims.\n",
    "- The historical datasets that ABC Corp uses will be downloaded as follows:\n",
    "    - [The Dow Jones Index](https://finance.yahoo.com/quote/%5EDJI/history/)\n",
    "    - [US Unemployemnt (Jobless Claims) data from the US Department of Labor](https://fred.stlouisfed.org/series/UNRATE)\n",
    "    - [Historical price of Crude Oil in the open market](https://fred.stlouisfed.org/series/MCOILBRENTEU)\n",
    "    - [New Housing Starts from US Census Beareau](https://fred.stlouisfed.org/series/HOUST#0)\n",
    "    - [Total Vehicles Sold](https://fred.stlouisfed.org/series/TOTALSA)\n",
    "    - [Retail Sales data from US Census Beareau](https://fred.stlouisfed.org/series/RSXFS)\n",
    "    - [Federal Interest Rates](https://fred.stlouisfed.org/series/FEDFUNDS])\n",
    "    - [The University of Michigan's Consumer Sentiment Survey](http://www.sca.isr.umich.edu/)  -- data to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning is highly dependent on the type of data and the task to be achieved. In our case we combine data from different sources and clean up the resulting dataframe. In image classification data, we may have to reshape the image sizes and create labels while a sentiment analysis dataset may need to be checked for spelling and keyword extraction.\n",
    "\n",
    "Moving forward, we will first import any libraries that we need to handle our data cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "import datetime\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Load all datasets (locate at `../data/` repository) to pandas DataFrames\n",
    "```python\n",
    ">>> dow     = \n",
    ">>> unemp   =\n",
    ">>> oil     = \n",
    ">>> hstarts = \n",
    ">>> cars    = \n",
    ">>> retail  = \n",
    ">>> fedrate = \n",
    ">>> umcsi   =\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = pd.read_csv('../data/Dow Jones Industrial Average DJI.csv')\n",
    "unemp = pd.read_csv('../data/Civilian Unemployment Rate UNRATE.csv')\n",
    "oil = pd.read_csv('../data/Crude Oil Prices MCOILBRENTEU.csv')\n",
    "hstarts = pd.read_csv('../data/Housing Starts HOUST.csv')\n",
    "cars = pd.read_csv('../data/Total_Vehicle_Sales_(TOTALSA).csv')\n",
    "retail = pd.read_csv('../data/Advance Retail Sales_RSXFS.csv')\n",
    "fedrate = pd.read_csv('../data/Federal Interest Rates FEDFUNDS.csv')\n",
    "umcsi=pd.read_csv(\"C:/Users/media/Downloads/tbmics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Visually inspect the dataframes\n",
    "    - 5 first rows for dow, umemp an oil\n",
    "    - 5 last rows for umcsi and cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date         Open         High          Low        Close  \\\n",
      "0  1985-01-01  1277.719971  1305.099976  1266.890015  1286.770020   \n",
      "1  1985-02-01  1276.939941  1307.530029  1263.910034  1284.010010   \n",
      "2  1985-03-01  1285.339966  1309.959961  1242.819946  1266.780029   \n",
      "3  1985-04-01  1264.800049  1290.300049  1245.800049  1258.060059   \n",
      "4  1985-05-01  1257.180054  1320.790039  1235.530029  1315.410034   \n",
      "\n",
      "     Adj Close     Volume  \n",
      "0  1286.770020   44450000  \n",
      "1  1284.010010  207300000  \n",
      "2  1266.780029  201050000  \n",
      "3  1258.060059  187110000  \n",
      "4  1315.410034  242250000  \n",
      "         DATE  UNRATE\n",
      "0  1948-01-01     3.4\n",
      "1  1948-02-01     3.8\n",
      "2  1948-03-01     4.0\n",
      "3  1948-04-01     3.9\n",
      "4  1948-05-01     3.5\n",
      "         DATE  MCOILBRENTEU\n",
      "0  1987-05-01         18.58\n",
      "1  1987-06-01         18.86\n",
      "2  1987-07-01         19.86\n",
      "3  1987-08-01         18.98\n",
      "4  1987-09-01         18.31\n",
      "           DATE  TOTALSA\n",
      "500  2017-09-01     18.9\n",
      "501  2017-10-01     18.4\n",
      "502  2017-11-01     17.9\n",
      "503  2017-12-01     18.2\n",
      "504  2018-01-01     17.5\n",
      "         Month  YYYY  ICS_ALL\n",
      "615     August  2021     70.3\n",
      "616  September  2021     72.8\n",
      "617    October  2021     71.7\n",
      "618   November  2021     67.4\n",
      "619   December  2021     70.6\n"
     ]
    }
   ],
   "source": [
    "dow1 = dow.head(5)\n",
    "print(dow1)\n",
    "unemp1=unemp.head(5)\n",
    "print(unemp1)\n",
    "oil1=oil.head(5)\n",
    "print(oil1)\n",
    "cars1=cars.tail(5)\n",
    "print(cars1)\n",
    "umcsi1=umcsi.tail(5)\n",
    "print(umcsi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Get the shape of the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 7)\n",
      "(841, 2)\n",
      "(369, 2)\n",
      "(709, 2)\n",
      "(505, 2)\n",
      "(313, 2)\n",
      "(763, 2)\n",
      "(620, 3)\n"
     ]
    }
   ],
   "source": [
    "dow_shape=dow.shape\n",
    "print(dow_shape)\n",
    "unemp_shape=unemp.shape\n",
    "print(unemp_shape)\n",
    "oil_shape=oil.shape \n",
    "print(oil_shape)\n",
    "hstarts_shape=hstarts.shape\n",
    "print(hstarts_shape)\n",
    "cars_shape=cars.shape\n",
    "print(cars_shape)\n",
    "retail_shape=retail.shape \n",
    "print(retail_shape)\n",
    "fedrate_shape=fedrate.shape\n",
    "print(fedrate_shape)\n",
    "umcsi_shape=umcsi.shape\n",
    "print(umcsi_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Get dataframe top rows view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>YYYY</th>\n",
       "      <th>ICS_ALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>November</td>\n",
       "      <td>1952</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  YYYY  ICS_ALL\n",
       "0  November  1952     86.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow.head(1)\n",
    "unemp.head(1)\n",
    "oil.head(1)\n",
    "hstarts.head(1)\n",
    "cars.head(1)\n",
    "retail.head(1)\n",
    "fedrate.head(1)\n",
    "umcsi.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Print the statistical charateristics of the datsets. \n",
    "    - Explain the output\n",
    "    > write your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of            Date          Open          High           Low         Close  \\\n",
      "0    1985-01-01   1277.719971   1305.099976   1266.890015   1286.770020   \n",
      "1    1985-02-01   1276.939941   1307.530029   1263.910034   1284.010010   \n",
      "2    1985-03-01   1285.339966   1309.959961   1242.819946   1266.780029   \n",
      "3    1985-04-01   1264.800049   1290.300049   1245.800049   1258.060059   \n",
      "4    1985-05-01   1257.180054   1320.790039   1235.530029   1315.410034   \n",
      "..          ...           ...           ...           ...           ...   \n",
      "394  2017-11-01  23442.900391  24327.820313  23242.750000  24272.349609   \n",
      "395  2017-12-01  24305.400391  24876.070313  23921.900391  24719.220703   \n",
      "396  2018-01-01  24809.349609  26616.710938  24741.699219  26149.390625   \n",
      "397  2018-02-01  26083.039063  26306.699219  23360.289063  25219.380859   \n",
      "398  2018-02-16  25165.939453  25432.419922  25149.259766  25219.380859   \n",
      "\n",
      "        Adj Close      Volume  \n",
      "0     1286.770020    44450000  \n",
      "1     1284.010010   207300000  \n",
      "2     1266.780029   201050000  \n",
      "3     1258.060059   187110000  \n",
      "4     1315.410034   242250000  \n",
      "..            ...         ...  \n",
      "394  24272.349609  7335640000  \n",
      "395  24719.220703  6589890000  \n",
      "396  26149.390625  9116920000  \n",
      "397  25219.380859  6494730000  \n",
      "398  25219.380859   406729453  \n",
      "\n",
      "[399 rows x 7 columns]>\n",
      "<bound method NDFrame.describe of            DATE  UNRATE\n",
      "0    1948-01-01     3.4\n",
      "1    1948-02-01     3.8\n",
      "2    1948-03-01     4.0\n",
      "3    1948-04-01     3.9\n",
      "4    1948-05-01     3.5\n",
      "..          ...     ...\n",
      "836  2017-09-01     4.2\n",
      "837  2017-10-01     4.1\n",
      "838  2017-11-01     4.1\n",
      "839  2017-12-01     4.1\n",
      "840  2018-01-01     4.1\n",
      "\n",
      "[841 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of            DATE  MCOILBRENTEU\n",
      "0    1987-05-01         18.58\n",
      "1    1987-06-01         18.86\n",
      "2    1987-07-01         19.86\n",
      "3    1987-08-01         18.98\n",
      "4    1987-09-01         18.31\n",
      "..          ...           ...\n",
      "364  2017-09-01         56.15\n",
      "365  2017-10-01         57.51\n",
      "366  2017-11-01         62.71\n",
      "367  2017-12-01         64.37\n",
      "368  2018-01-01         69.08\n",
      "\n",
      "[369 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of            DATE   HOUST\n",
      "0    1959-01-01  1657.0\n",
      "1    1959-02-01  1667.0\n",
      "2    1959-03-01  1620.0\n",
      "3    1959-04-01  1590.0\n",
      "4    1959-05-01  1498.0\n",
      "..          ...     ...\n",
      "704  2017-09-01  1159.0\n",
      "705  2017-10-01  1261.0\n",
      "706  2017-11-01  1299.0\n",
      "707  2017-12-01  1209.0\n",
      "708  2018-01-01  1326.0\n",
      "\n",
      "[709 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of            DATE  TOTALSA\n",
      "0    1976-01-01     12.8\n",
      "1    1976-02-01     13.3\n",
      "2    1976-03-01     13.4\n",
      "3    1976-04-01     13.2\n",
      "4    1976-05-01     13.0\n",
      "..          ...      ...\n",
      "500  2017-09-01     18.9\n",
      "501  2017-10-01     18.4\n",
      "502  2017-11-01     17.9\n",
      "503  2017-12-01     18.2\n",
      "504  2018-01-01     17.5\n",
      "\n",
      "[505 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of            DATE   RSXFS\n",
      "0    1992-01-01  146913\n",
      "1    1992-02-01  147270\n",
      "2    1992-03-01  146831\n",
      "3    1992-04-01  148082\n",
      "4    1992-05-01  149015\n",
      "..          ...     ...\n",
      "308  2017-09-01  429623\n",
      "309  2017-10-01  432584\n",
      "310  2017-11-01  436032\n",
      "311  2017-12-01  435673\n",
      "312  2018-01-01  434364\n",
      "\n",
      "[313 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of            DATE  FEDFUNDS\n",
      "0    1954-07-01      0.80\n",
      "1    1954-08-01      1.22\n",
      "2    1954-09-01      1.06\n",
      "3    1954-10-01      0.85\n",
      "4    1954-11-01      0.83\n",
      "..          ...       ...\n",
      "758  2017-09-01      1.15\n",
      "759  2017-10-01      1.15\n",
      "760  2017-11-01      1.16\n",
      "761  2017-12-01      1.30\n",
      "762  2018-01-01      1.41\n",
      "\n",
      "[763 rows x 2 columns]>\n",
      "<bound method NDFrame.describe of          Month  YYYY  ICS_ALL\n",
      "0     November  1952     86.2\n",
      "1     February  1953     90.7\n",
      "2       August  1953     80.8\n",
      "3     November  1953     80.7\n",
      "4     February  1954     82.0\n",
      "..         ...   ...      ...\n",
      "615     August  2021     70.3\n",
      "616  September  2021     72.8\n",
      "617    October  2021     71.7\n",
      "618   November  2021     67.4\n",
      "619   December  2021     70.6\n",
      "\n",
      "[620 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "dow_stat=dow.describe\n",
    "print(dow_stat)\n",
    "unemp_stat=unemp.describe\n",
    "print(unemp_stat)\n",
    "oil_stat=oil.describe \n",
    "print(oil_stat)\n",
    "hstarts_stat=hstarts.describe\n",
    "print(hstarts_stat)\n",
    "cars_stat=cars.describe\n",
    "print(cars_stat)\n",
    "retail_stat=retail.describe\n",
    "print(retail_stat)\n",
    "fedrate_stat=fedrate.describe\n",
    "print(fedrate_stat)\n",
    "umcsi_stat=umcsi.describe\n",
    "print(umcsi_stat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Which datasets have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(dow.isnull().sum().sum())\n",
    "print(unemp.isnull().sum().sum())\n",
    "print(hstarts.isnull().sum().sum())\n",
    "print(cars.isnull().sum().sum())\n",
    "print(retail.isnull().sum().sum())\n",
    "print(fedrate.isnull().sum().sum())\n",
    "print(umcsi.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- What are your observations ?\n",
    "> write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: dow dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Drop column volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Volume'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_43816/1481161363.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Volume'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#this error because i excecute it twice so the code didn't find the 'Volume'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\media\\Desktop\\python-for-finance\\python-for-finance\\main_env\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\media\\Desktop\\python-for-finance\\python-for-finance\\main_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4904\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4905\u001b[0m         \"\"\"\n\u001b[1;32m-> 4906\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4907\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4908\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\media\\Desktop\\python-for-finance\\python-for-finance\\main_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4150\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\media\\Desktop\\python-for-finance\\python-for-finance\\main_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4185\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\media\\Desktop\\python-for-finance\\python-for-finance\\main_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Volume'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dow.drop('Volume')\n",
    "print(dow)\n",
    "#this error because i excecute it twice so the code didn't find the 'Volume'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Rename columns to upper case to match other dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DATE          OPEN          HIGH           LOW         CLOSE  \\\n",
      "0    1985-01-01   1277.719971   1305.099976   1266.890015   1286.770020   \n",
      "1    1985-02-01   1276.939941   1307.530029   1263.910034   1284.010010   \n",
      "2    1985-03-01   1285.339966   1309.959961   1242.819946   1266.780029   \n",
      "3    1985-04-01   1264.800049   1290.300049   1245.800049   1258.060059   \n",
      "4    1985-05-01   1257.180054   1320.790039   1235.530029   1315.410034   \n",
      "..          ...           ...           ...           ...           ...   \n",
      "394  2017-11-01  23442.900391  24327.820313  23242.750000  24272.349609   \n",
      "395  2017-12-01  24305.400391  24876.070313  23921.900391  24719.220703   \n",
      "396  2018-01-01  24809.349609  26616.710938  24741.699219  26149.390625   \n",
      "397  2018-02-01  26083.039063  26306.699219  23360.289063  25219.380859   \n",
      "398  2018-02-16  25165.939453  25432.419922  25149.259766  25219.380859   \n",
      "\n",
      "        ADJ CLOSE  \n",
      "0     1286.770020  \n",
      "1     1284.010010  \n",
      "2     1266.780029  \n",
      "3     1258.060059  \n",
      "4     1315.410034  \n",
      "..            ...  \n",
      "394  24272.349609  \n",
      "395  24719.220703  \n",
      "396  26149.390625  \n",
      "397  25219.380859  \n",
      "398  25219.380859  \n",
      "\n",
      "[399 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#no Volume founded\n",
    "dow.columns = ['DATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'ADJ CLOSE']\n",
    "print(dow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Create 'Year' column with int values instead of float. Use function bellow:\n",
    "\n",
    "```python\n",
    ">>> def to_int(x):\n",
    ">>>     return int(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Month  YYYY  ICS_ALL\n",
      "0     November  1952     86.2\n",
      "1     February  1953     90.7\n",
      "2       August  1953     80.8\n",
      "3     November  1953     80.7\n",
      "4     February  1954     82.0\n",
      "..         ...   ...      ...\n",
      "615     August  2021     70.3\n",
      "616  September  2021     72.8\n",
      "617    October  2021     71.7\n",
      "618   November  2021     67.4\n",
      "619   December  2021     70.6\n",
      "\n",
      "[620 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(umcsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Month  YYYY  ICS_ALL  Year\n",
      "0     November  1952     86.2  1952\n",
      "1     February  1953     90.7  1953\n",
      "2       August  1953     80.8  1953\n",
      "3     November  1953     80.7  1953\n",
      "4     February  1954     82.0  1954\n",
      "..         ...   ...      ...   ...\n",
      "615     August  2021     70.3  2021\n",
      "616  September  2021     72.8  2021\n",
      "617    October  2021     71.7  2021\n",
      "618   November  2021     67.4  2021\n",
      "619   December  2021     70.6  2021\n",
      "\n",
      "[620 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def to_int(x):\n",
    "    return int(x)\n",
    "umcsi['Year'] = umcsi['YYYY'].apply(to_int)\n",
    "print(umcsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: umcsi dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Drop NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no NaN values founds in my csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Combine year columns to one column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1952-11-01\n",
      "1     1953-02-01\n",
      "2     1953-08-01\n",
      "3     1953-11-01\n",
      "4     1954-02-01\n",
      "         ...    \n",
      "615   2021-08-01\n",
      "616   2021-09-01\n",
      "617   2021-10-01\n",
      "618   2021-11-01\n",
      "619   2021-12-01\n",
      "Name: DATE, Length: 620, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "umcsi['DATE'] = umcsi.apply(lambda x: datetime.datetime.strptime(\"{0} {1}\".format(x['YYYY'],x['Month']), \"%Y %B\"),axis=1)\n",
    "print(umcsi['DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Turn date format to string to match other DATE's for umcsi dataset. We'll merge the data on this column so this is a vital step. Use the function bellow:\n",
    "\n",
    "```python\n",
    ">>> def to_str(x):\n",
    ">>>     return str(x)[:10]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1952-11-01\n",
      "1      1953-02-01\n",
      "2      1953-08-01\n",
      "3      1953-11-01\n",
      "4      1954-02-01\n",
      "          ...    \n",
      "615    2021-08-01\n",
      "616    2021-09-01\n",
      "617    2021-10-01\n",
      "618    2021-11-01\n",
      "619    2021-12-01\n",
      "Name: DATE, Length: 620, dtype: object\n",
      "         Month  YYYY  ICS_ALL        DATE\n",
      "0     November  1952     86.2  1952-11-01\n",
      "1     February  1953     90.7  1953-02-01\n",
      "2       August  1953     80.8  1953-08-01\n",
      "3     November  1953     80.7  1953-11-01\n",
      "4     February  1954     82.0  1954-02-01\n",
      "..         ...   ...      ...         ...\n",
      "615     August  2021     70.3  2021-08-01\n",
      "616  September  2021     72.8  2021-09-01\n",
      "617    October  2021     71.7  2021-10-01\n",
      "618   November  2021     67.4  2021-11-01\n",
      "619   December  2021     70.6  2021-12-01\n",
      "\n",
      "[620 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def to_str(x):\n",
    "    return str(x)[:10]\n",
    "\n",
    "umcsi['DATE'] = umcsi['DATE'].apply(to_str)\n",
    "print(umcsi['DATE'])\n",
    "print(umcsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Drop unneeded columns for umcsi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ICS_ALL        DATE\n",
      "0       86.2  1952-11-01\n",
      "1       90.7  1953-02-01\n",
      "2       80.8  1953-08-01\n",
      "3       80.7  1953-11-01\n",
      "4       82.0  1954-02-01\n",
      "..       ...         ...\n",
      "615     70.3  2021-08-01\n",
      "616     72.8  2021-09-01\n",
      "617     71.7  2021-10-01\n",
      "618     67.4  2021-11-01\n",
      "619     70.6  2021-12-01\n",
      "\n",
      "[620 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "umcsi.drop(['YYYY','Month'],axis=1,inplace=True)\n",
    "print(umcsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Move 'DATE' column to the front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DATE  ICS_ALL\n",
      "0    1952-11-01     86.2\n",
      "1    1953-02-01     90.7\n",
      "2    1953-08-01     80.8\n",
      "3    1953-11-01     80.7\n",
      "4    1954-02-01     82.0\n",
      "..          ...      ...\n",
      "615  2021-08-01     70.3\n",
      "616  2021-09-01     72.8\n",
      "617  2021-10-01     71.7\n",
      "618  2021-11-01     67.4\n",
      "619  2021-12-01     70.6\n",
      "\n",
      "[620 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "List = list(umcsi)\n",
    "List.insert(0, List.pop(List.index('DATE')))\n",
    "umcsi = umcsi.reindex(columns = List)\n",
    "print(umcsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Concatenate all dataframes into one final dataframe using `lambda` function\n",
    "    - Use the function `reduce` imported from `functools` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Remove all rows with outliers in at least one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Change the DATE column from String to python's datetime.datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Rename columns to more user friendly names. Use the code bellow:\n",
    "\n",
    "```python\n",
    ">>> df.columns = ['DATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'ADJ CLOSE', 'VOLUME', 'UNEMP %','OIL PRICE','NEW HOMES','NEW CARS SOLD', 'RETAIL SALES','FED INTRST %','CSI' ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Visualize a few basic end data characteristics.\n",
    "<img src=\"../data/DowJonesIndustrials.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"../data/FederalInterestRate.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"../data/BrentCrudeOilperbarrel.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<img src=\"../data/NewHomeStarts.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Plot the correclation matrix. What's you observations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- Drop the less useful columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8- Create a new column / feature from subtracting the LOW and HIGH column called SPREAD which is the difference between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9- Move the SPREAD column next to CLOSE as they are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10- Reset the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11- View final dataframe correlation matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12- Compare your final result with data on file `../data/cleaned_timeseries.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13- What's your conclusion ?\n",
    "> Write you answer here"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
